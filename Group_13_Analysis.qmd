---
title: "Group_13_Analysis"
author: "Shuyin Chen, Xuran Wang, Yingying Zhuo, Yunfei Chen, Yuxuan Li "
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf: default
editor_options: 
  chunk_output_type: console
execute:
  echo: true
  eval: true
  warning: false
  message: false
---

# Library

```{r}
#| label: libraries
library(ggplot2)
library(readr)
library(tidyverse)
library(knitr)
library(stringr)
library(jtools)
library(GGally)
library(gridExtra)
library(factoextra)
```

# Wrangling of data

```{r}
data <- read.csv("dataset13.csv")

str(data)
summary(data)
# Remove missing values
data <- na.omit(data)
# Delete data with an altitude greater than 8848 (world's highest point at 8848m).
data <- data[data$altitude_mean_meters <= 8848, ]
str(data)
# Convert Qualityclass category variables to 0, 1: Good=1, Poor=0
data$Qualityclass_binary <- ifelse(data$Qualityclass == "Good", 1, 0)
#Treat harvested as a category variable
data$harvested <- as.factor(data$harvested)
str(data)

```

# Data visualisation

Plotting boxplots of aroma, flavour and acidity.

```{r}
# Create boxplots to see the basic structure of the data
g1 <- ggplot(data = data, aes(x = Qualityclass, y = aroma, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "Aroma")+ 
  theme(legend.position = "none")
g2 <- ggplot(data = data, aes(x = Qualityclass, y = flavor, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "Flavor")+ 
  theme(legend.position = "none")
g3 <- ggplot(data = data, aes(x = Qualityclass, y = acidity, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "Acidity")+ 
  theme(legend.position = "none")
grid.arrange(g1,g2,g3, ncol=3)

```
The distribution of these three variables describing the characteristics of the coffee beans was around 7.5, with the Good category having overall larger values than the Poor category. An outlier with a value of 0 can be seen in the boxplots for the Poor category.


Then,plotting boxplots of Category_two_defects and Altitude_mean_meters.

```{r}
# Boxplot
ggplot(data = data, aes(x = Qualityclass, y = category_two_defects, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "Category_two_defects")+ 
  theme(legend.position = "none")
ggplot(data = data, aes(x = Qualityclass, y = altitude_mean_meters, fill = Qualityclass)) +
  geom_boxplot() +
  labs(x = "Qualityclass", y = "Altitude_mean_meters")+ 
  theme(legend.position = "none")

```

In order to investigate whether there is any relationship between coffee quality and the year of harvest, we draw a bar chart of the number of good and poor coffees in different years of harvest after turning the year of harvest into a categorical variable.

```{r}
# Creating a barplot of havests to see the distributional characteristics of harvest years
ggplot(data = data, aes(x = harvested, fill = Qualityclass)) +
  geom_bar(position="dodge",stat="count") +
  labs(x = "Harvested", y = "Proportion") +
  theme(legend.position = "right")
```

It is not obvious from the above graph that there is a clear relationship between the quality of coffee and the year of harvest.

Check correlations, distribution and print correlation coefficient

```{r}
#| eval: true
#scartterplot
par(mfrow = c(1, 1))

# Check correlations (as scatterplots), distribution and print correlation coefficient 
ggpairs(data[,2:6], 
        title = "Scatterplot matrix of coffee data", 
        mapping = aes(color = data$Qualityclass))

```

Create a correlation matrix as heatmap

```{r}
# Create a heat map based on the correlation matrix of the variables to see 
 if multicollinearity exists
# Calculate the correlation matrix for numerical variables
numeric_vars <- data[,2:6]
cor_matrix <- cor(numeric_vars)
print(cor_matrix)
# Create the heat map
cor_melt <- reshape2::melt(cor_matrix)
ggplot(data = cor_melt, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(x='', y='', title='Correlation Matrix of Coffee Data Variables')
```

Delete the outliers for the variables aroma, flavor and acidity.

```{r}
# delete Aroma, flavor and acidity== 0 
data <- data[data$aroma != 0, ]
data <- data[data$flavor != 0, ]
data <- data[data$acidity != 0, ]
```

# PCA

Due to the significant multicollinearity between these three variables, a principal component analysis was performed to obtain the loading matrix and the scree plot.

```{r}
# pca for aroma flavor acidity
varable3 <- scale(data[, 2:4])
pca_result <- prcomp(varable3, center = TRUE, scale. = TRUE)
fviz_pca_ind(pca_result)

# Explain the variance
print(summary(pca_result))
# The first principal component explains 79.18% of the variance

# Principal component loading
print(pca_result$rotation)
# The loadings of three variables in the first principal component are nearly equal,
  so the first principal component can be interpreted as the average level of acidity,
  flavor and aroma of the coffee. 

variance <- pca_result$sdev^2
variance_percentage <- variance / sum(variance) * 100
plot(variance_percentage, type = "b", xlab = "Principal Component", ylab = "Percentage of Variance Explained", main = "Scree Plot")
text(variance_percentage, labels = paste("PC", 1:length(variance_percentage)), pos = 4)
```

According to the loading matrix, it can be seen that the first principal component explains 79.18% of these three variables, so the first principal component is selected as the variable of the model. It can be interpreted as the average of the three variables aroma, flavour, and acidity based on the score coefficient of the first principal component.

```{r}
# Name pca1 as characteristics
pca1 <- as.data.frame(pca_result$x[, 1])
colnames(pca1) <- "characteristics"
head(pca1)
# Re-verify the correlation between the variables
data1 <- cbind(characteristics = pca1, data[, c(5:7,1,8:9)])
str(data1)

# Export Variable names and types for the Variables
variable_info <- data.frame(variable_name = names(data1), 
                            data_type = sapply(data1, class), row.names = NULL)

##write.csv(variable_info, "variable_info.csv", row.names = FALSE)

ggpairs(data1[,1:3], 
        title = "Scatterplot matrix of coffee data", 
        mapping = aes(color = data1$Qualityclass))

# Create scatterplot of harvested(after changing into categorical variables)
ggpairs(data[,7:8],
        title = "Scatterplot of harvested", 
        mapping = aes(color = data$Qualityclass))
```

Based on the scatterplot matrix, it can be seen that there is no multicollinearity in the newly merged dataset and binary logistic regression can be performed.

$$characteristics_{\mbox{i}} =
0.56 \cdot aroma_{\mbox{i}} +
0.60 \cdot flavor_{\mbox{i}} - 0.57 \cdot acidity_{\mbox{i}}$$

# Creating model

```{r}
# Create the formula
formula1 <- as.formula(paste("Qualityclass_binary ~", 
                       paste(names(data1)[1:5], 
                       collapse = "+")))

# Fit model for the Qualityclass_binary
logistic_model1 <- glm(formula1, data = data1, family = binomial)

summary(logistic_model1)
# Filter variables using stepwise regression
stepwise_model <- step(logistic_model1)

summary(stepwise_model)
```

```{r}
model_deviance <- deviance(stepwise_model)
null_deviance <- deviance(glm(Qualityclass_binary ~ 1, 
                          family = binomial, 
                          data = data1))
# Calculate R_square
R_square <- 1 - (model_deviance / null_deviance)
R_square
```

```{r}
# Output model results
model_summary <- summary(stepwise_model)

coefficients_table <- model_summary$coefficients

write.csv(coefficients_table, "logistic_model_summary.csv", row.names = TRUE)

```

According to our analysis, we can get the fitted modelï¼š

$$ \ln\left(\frac{P({Qualityclass_i} = 1)}{1 - P({Qualityclass_i} = 1)}\right) = \alpha + \beta \cdot {characteristics}_i + \sum (\gamma_j \cdot {CountryVariables}_{ij}) $$

where

1.  ${Qualityclass_i}$ is the response variable for the $i_{th}$ observation, indicating the quality classification of coffee. ${Qualityclass_i}=1$ means coffee's quality is good.

2.  $\alpha$ is the baseline log-odds when all explanatory variables are equal to zero.

3.  $\beta$ is the coefficient for the characteristics feature. It indicates the impact of this feature on the log-odds of coffee quality being good.

4.  ${characteristics}_i$ is the main characteristic derived from PCA analysis for the $i_{th}$ observation.

5.  $\gamma_j$ is the impact of specific $j_th$ countries of origin on coffee quality.

6.  ${CountryVariables}_{ij}$ are dummy variables for the $j_th$ country of origin for the $i_{th}$ observation.
